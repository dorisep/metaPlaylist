{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "from spotify_client import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_accesss_token():\n",
    "    client_creds = f'{client_id}:{client_secret}'\n",
    "    client_creds_b64 = base64.b64encode(client_creds.encode())\n",
    "\n",
    "    refresh_token_header = {\n",
    "        'Authorization' : f'Basic {client_creds_b64.decode()}'\n",
    "    }\n",
    "\n",
    "    # def refresh_playlist_token():\n",
    "    refresh_url =  'https://accounts.spotify.com/api/token'\n",
    "    refresh_params = {\n",
    "        'grant_type': 'refresh_token',\n",
    "        'refresh_token': 'AQA92cE5oL-fTQvG1_objGmNUVNQ_6AseJUqjsNC2ujDEFeMTOPxBpLqQ6Ct2tkmLIp79RT6deD3WjdPRYDlhnU2YgautBPNYw5aGMjYVD-y35lz5_n1L88yxG2UA-7nd58'\n",
    "        \n",
    "    }\n",
    "\n",
    "    refresh_data = urlencode(refresh_params)\n",
    "\n",
    "\n",
    "\n",
    "    r_token = requests.post(refresh_url, data=refresh_params, headers=refresh_token_header)\n",
    "\n",
    "    refresh_response = r_token.json()\n",
    "\n",
    "    access_token = refresh_response['access_token']\n",
    "\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_week_num():\n",
    "playlist_token = refresh_accesss_token()\n",
    "csv_path = path\n",
    "def get_week_num():\n",
    "    my_date = datetime.date.today() \n",
    "    year, week_num, day_of_week = my_date.isocalendar()\n",
    "    this_week = week_num\n",
    "    return this_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_tracks(album_ids):\n",
    "    track_ids = []\n",
    "#     request_data = json.dumps(uris)\n",
    "    for album_id in album_ids:\n",
    "        query = f'https://api.spotify.com/v1/albums/{album_id}/tracks'\n",
    "        response = requests.get(\n",
    "            query,\n",
    "            headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Authorization': f'Bearer {playlist_token}'\n",
    "            })\n",
    "        response_json = response.json()\n",
    "#         print(response_json)\n",
    "        tracks = response_json['items']\n",
    "        for track in tracks:\n",
    "            track_ids.append(track['uri'])\n",
    "    return track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_for_albums(csv_path):\n",
    "artists=[]\n",
    "albums=[]\n",
    "albums_not_found = {'artist': [], 'album': []}\n",
    "album_ids = set()\n",
    "#     week_num = get_week_num()\n",
    "week_num = 14\n",
    "output_path = os.path.join('..','..', 'data', 'test',f'albums_not_found_wk_{week_num}.csv')\n",
    "\n",
    "\n",
    "#     read in weekly metaScrape csv \n",
    "with open(csv_path, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "#         filter for artists and albums from current week\n",
    "        if int(row['week_num'])==week_num:\n",
    "            artists.append(row['artist'])\n",
    "            albums.append(row['album'])\n",
    "#   initialize spotify client\n",
    "spotify = SpotifyAPI(client_id, client_secret)\n",
    "for al, ar in zip(albums, artists):\n",
    "#   search for album ids \n",
    "    temp = spotify.search({\"album\":al, \"artist\":ar}, search_type=\"album\")\n",
    "    try:\n",
    "        parse_album_ids = (temp[\"albums\"][\"items\"][0][\"id\"])\n",
    "#   create dicitonary for albums not found\n",
    "    except:\n",
    "        albums_not_found['artist'] = ar\n",
    "        albums_not_found['album'] = al\n",
    "#     album_ids.add(parse_album_ids)\n",
    "# try:\n",
    "with open(output_path, 'w') as csvfile:\n",
    "    fieldnames = ['artist', 'album']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(albums_not_found.values())\n",
    "# print(albums_not_found.values())\n",
    "\n",
    "#             writer.writerow(data)\n",
    "#     except IOError:\n",
    "#         print(\"I/O error\")\n",
    "#         return(get_album_tracks(album_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tracks_to_playlist(playlist_id):\n",
    "    track_ids = [track for track in search_for_albums(csv_path)]\n",
    "    track_limit = 100 \n",
    "    # using list comprehension \n",
    "    batched_tracks = [track_ids[i * track_limit:(i + 1) * track_limit] for i in range((len(track_ids) + track_limit - 1) // track_limit)]  \n",
    "    url = f'https://api.spotify.com/v1/playlists/{playlist_id}/tracks'\n",
    "\n",
    "    for batch in batched_tracks:\n",
    "\n",
    "        request_data = json.dumps(batch)\n",
    "\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            data=request_data,\n",
    "            headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {playlist_token}'\n",
    "            })\n",
    "        return(response.json())\n",
    "\n",
    "def create_playlist():\n",
    "#     week_num = get_week_num()\n",
    "    week_num = 14\n",
    "    request_body = json.dumps({\n",
    "        'name': f'2021-week {week_num} scrape',\n",
    "        'description': f'metacritic rated albums for the {week_num}th of the year',\n",
    "        'public': True\n",
    "    })\n",
    "    url = f'https://api.spotify.com/v1/users/{spotify_user_id}/playlists'\n",
    "\n",
    "\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data = request_body,\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {playlist_token}'\n",
    "\n",
    "    })\n",
    "    response_json = response.json()\n",
    "#     print(response_json)\n",
    "    playlist_id = (response_json['id'])\n",
    "\n",
    "    return add_tracks_to_playlist(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_playlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_week_num():\n",
    "playlist_token = refresh_accesss_token()\n",
    "csv_path = path\n",
    "def get_week_num():\n",
    "    my_date = datetime.date.today() \n",
    "    year, week_num, day_of_week = my_date.isocalendar()\n",
    "    this_week = week_num\n",
    "    return this_week\n",
    "\n",
    "def get_album_tracks(album_ids):\n",
    "    track_ids = []\n",
    "#     request_data = json.dumps(uris)\n",
    "    for album_id in album_ids:\n",
    "        query = f'https://api.spotify.com/v1/albums/{album_id}/tracks'\n",
    "        response = requests.get(\n",
    "            query,\n",
    "            headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Authorization': f'Bearer {playlist_token}'\n",
    "            })\n",
    "        response_json = response.json()\n",
    "#         print(response_json)\n",
    "        tracks = response_json['items']\n",
    "        for track in tracks:\n",
    "            track_ids.append(track['uri'])\n",
    "    return track_ids\n",
    "\n",
    "def search_for_albums(csv_path):\n",
    "    artists=[]\n",
    "    albums=[]\n",
    "    albums_not_found = {'artist': [], 'album': []}\n",
    "    album_ids = set()\n",
    "\n",
    "#     read in weekly metaScrape csv \n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "#         filter for artists and albums from current week\n",
    "            if int(row['week_num'])==get_week_num():\n",
    "                artists.append(row['artist'])\n",
    "                albums.append(row['album'])\n",
    "#   initialize spotify client\n",
    "    spotify = SpotifyAPI(client_id, client_secret)\n",
    "    for al, ar in zip(albums, artists):\n",
    "#   search for album ids \n",
    "        temp = spotify.search({\"album\":al, \"artist\":ar}, search_type=\"album\")\n",
    "        try:\n",
    "            parse_album_ids = (temp[\"albums\"][\"items\"][0][\"id\"])\n",
    "#   create dicitonary for albums not found\n",
    "        except:\n",
    "            albums_not_found['artist'].append(ar)\n",
    "            albums_not_found['album'].append(al)\n",
    "        album_ids.add(parse_album_ids)\n",
    "    return(get_album_tracks(album_ids))\n",
    "'''\n",
    " response body contains an object whose key is \"audio_features\" and whose value is an array of \n",
    " audio features objects in JSON format.\n",
    " \n",
    "Objects are returned in the order requested. If an object is not found, a null value is returned in the appropriate position. \n",
    "Duplicate ids in the query will result in duplicate objects in the response. \n",
    "On error, the header status code is an error code and the response body contains an error object.\n",
    "\n",
    "'''\n",
    "def get_track_features():\n",
    "    track_ids = [track for track in search_for_albums(csv_path)]\n",
    "    track_limit = 100 \n",
    "    # using list comprehension \n",
    "    batched_tracks = [track_ids[i * track_limit:(i + 1) * track_limit] for i in range((len(track_ids) + track_limit - 1) // track_limit)]  \n",
    "\n",
    "    for batch in batched_tracks:\n",
    "\n",
    "        request_data = json.dumps(batch)\n",
    "        url = f'https://api.spotify.com/v1/audio-features?ids={request_data}'\n",
    "\n",
    "        response = requests.get(\n",
    "            url,\n",
    "            headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {playlist_token}'\n",
    "            })\n",
    "        for k in response:\n",
    "            print(dir(k))\n",
    "            for v in k:\n",
    "                print(dir(v))\n",
    "                break\n",
    "            break\n",
    "       \n",
    "    \n",
    "\n",
    "def add_tracks_to_playlist(playlist_id):\n",
    "    get_track_features()\n",
    "    track_ids = [track for track in search_for_albums(csv_path)]\n",
    "    track_limit = 100 \n",
    "    # using list comprehension \n",
    "    batched_tracks = [track_ids[i * track_limit:(i + 1) * track_limit] for i in range((len(track_ids) + track_limit - 1) // track_limit)]  \n",
    "    url = f'https://api.spotify.com/v1/playlists/{playlist_id}/tracks'\n",
    "\n",
    "    for batch in batched_tracks:\n",
    "\n",
    "        request_data = json.dumps(batch)\n",
    "\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            data=request_data,\n",
    "            headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {playlist_token}'\n",
    "            })\n",
    "    return(response.json())\n",
    "\n",
    "def create_playlist():\n",
    "    week_num = get_week_num()\n",
    "    request_body = json.dumps({\n",
    "        'name': f'2021-week {week_num} scrape',\n",
    "        'description': f'metacritic rated albums for the {week_num}th of the year',\n",
    "        'public': True\n",
    "    })\n",
    "    url = f'https://api.spotify.com/v1/users/{spotify_user_id}/playlists'\n",
    "\n",
    "\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data = request_body,\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {playlist_token}'\n",
    "\n",
    "    })\n",
    "    response_json = response.json()\n",
    "#     print(response_json)\n",
    "    playlist_id = (response_json['id'])\n",
    "\n",
    "    return add_tracks_to_playlist(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'center', 'count', 'decode', 'endswith', 'expandtabs', 'find', 'fromhex', 'hex', 'index', 'isalnum', 'isalpha', 'isascii', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n",
      "['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'as_integer_ratio', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snapshot_id': 'MywwNTUyZDlhYTVkYjljNWRiMjAxNTJhOGUwZjM2ZTk3NmQ5NjNlY2U1'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_playlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
