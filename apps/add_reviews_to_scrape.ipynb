{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7d6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d32c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set here to provide data to test code\n",
    "\n",
    "# my_date = datetime.date.today() \n",
    "# year, week_num, day_of_week = my_date.isocalendar()\n",
    "# this_week = week_num\n",
    "\n",
    "# url_for_scrape = 'https://www.metacritic.com/browse/albums/release-date/new-releases/date'\n",
    "# user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "# # send response\n",
    "# response_score = requests.get(url_for_scrape, headers = user_agent)\n",
    "# # scrape website into variable to parse\n",
    "# soup_score = BeautifulSoup(response_score.text, 'html.parser')\n",
    "\n",
    "# # create temporary lists for user scores\n",
    "# userP = []\n",
    "# userM = []\n",
    "# userN = []\n",
    "# # create/initialize dictionary \n",
    "# albums_dict = {'artist':[], 'album':[], 'date':[], 'week_num':[], 'meta_score': [], 'user_score':[]}\n",
    "\n",
    "# soup_score.find_all('td', class_='clamp-summary-wrap')\n",
    "# # create soup \n",
    "# for _ in soup_score.find_all('td', class_='clamp-summary-wrap'):\n",
    "#     # scrape album name\n",
    "#     albums_dict['album'].append(_.find('a', class_= 'title').text)\n",
    "#     # scrape artist name and strip white space and extra characters\n",
    "#     albums_dict['artist'].append(_.find('div', class_='artist').text.strip().lstrip('by '))\n",
    "#     # scrape date\n",
    "#     albums_dict['date'].append(_.find('div', class_='clamp-details').find('span').text)\n",
    "#     # scrape meta_score, handle for changes in class name, convert data type of score to int and append to dict\n",
    "#     # except set to pass since all alubms have a score\n",
    "\n",
    "#     try:\n",
    "#         albums_dict['meta_score'].append(int(_.find('div', class_='metascore_w large release positive').text))  \n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         albums_dict['meta_score'].append(int(_.find('div', class_='metascore_w large release mixed').text))  \n",
    "#     except:\n",
    "#         pass \n",
    "#     try:\n",
    "#         albums_dict['meta_score'].append(int(_.find('div', class_='metascore_w large release negative').text))  \n",
    "#     except:\n",
    "#         pass\n",
    "#     # scrape user score, handle errors for tbd/class name and append to temp list\n",
    "#     try:\n",
    "#         userP.append(float(_.find('div', class_='metascore_w user large release positive').text))  \n",
    "#     except:\n",
    "#         userP.append(0)\n",
    "#     try:\n",
    "#         userM.append(float(_.find('div', class_='metascore_w user large release mixed').text))  \n",
    "#     except:\n",
    "#         userM.append(0)\n",
    "#     try:\n",
    "#         userN.append(float(_.find('div', class_='metascore_w user large release negative').text))  \n",
    "#     except:\n",
    "#         userN.append(0)\n",
    "\n",
    "# # merge user score by filtering scores from tbd using data type in temporary lists, convert data type of scores to int and append to dictionary        \n",
    "# for a, b, c in zip(userP, userM, userN):\n",
    "#     if isinstance(a, float):\n",
    "#         albums_dict['user_score'].append(int(a * 10))\n",
    "#     elif isinstance(b, float):\n",
    "#         albums_dict['user_score'].append(int(b * 10))\n",
    "#     elif isinstance(c, float):\n",
    "#         albums_dict['user_score'].append(int(c * 10))\n",
    "#     else:\n",
    "#         albums_dict['user_score'].append(c)\n",
    "# # create week_num key and values for weekly scrape\n",
    "# for dates in albums_dict['date']:\n",
    "#     albums_dict['week_num'].append((datetime.datetime.strptime(dates, '%B %d, %Y')).isocalendar()[1])\n",
    "# # write dictionary to csv\n",
    "# # create header\n",
    "# fields = ['artist', 'album', 'date', 'week_num', 'meta_score', 'user_score'] \n",
    "# # create variable for data to be written\n",
    "# data = zip(albums_dict['artist'], albums_dict['album'], albums_dict['date'], albums_dict['week_num'], albums_dict['meta_score'], albums_dict['user_score'])\n",
    "# output_path = os.path.join('..', 'data', 'meta_scrape.csv')\n",
    "# # create header\n",
    "# fields = ['artist', 'album', 'date', 'week_num', 'meta_score', 'user_score'] \n",
    "# # create variable for data to be written\n",
    "# data = zip(\n",
    "#         albums_dict['artist'], \n",
    "#         albums_dict['album'], \n",
    "#         albums_dict['date'], \n",
    "#         albums_dict['week_num'], \n",
    "#         albums_dict['meta_score'], \n",
    "#         albums_dict['user_score']\n",
    "#         )\n",
    "# with open(output_path, 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerow(fields)\n",
    "#     for d in data:\n",
    "#         writer.writerow(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf1738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('..', 'data', 'meta_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5315092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>date</th>\n",
       "      <th>week_num</th>\n",
       "      <th>meta_score</th>\n",
       "      <th>user_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snail Mail</td>\n",
       "      <td>Valentine</td>\n",
       "      <td>November 5, 2021</td>\n",
       "      <td>44</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The War on Drugs</td>\n",
       "      <td>I Don't Live Here Anymore</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mastodon</td>\n",
       "      <td>Hushed and Grim</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geese</td>\n",
       "      <td>Projector</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Equals</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mickey Guyton</td>\n",
       "      <td>Remember Her Name</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Alessia Cara</td>\n",
       "      <td>In the Meantime</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RP Boo</td>\n",
       "      <td>Established!</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>The Roadside [EP]</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Moor Mother</td>\n",
       "      <td>Black Encyclopedia of the Air</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                          album                date  \\\n",
       "0         Snail Mail                      Valentine    November 5, 2021   \n",
       "1   The War on Drugs      I Don't Live Here Anymore    October 29, 2021   \n",
       "2           Mastodon                Hushed and Grim    October 29, 2021   \n",
       "3              Geese                      Projector    October 29, 2021   \n",
       "4         Ed Sheeran                         Equals    October 29, 2021   \n",
       "..               ...                            ...                 ...   \n",
       "95     Mickey Guyton              Remember Her Name  September 24, 2021   \n",
       "96      Alessia Cara                In the Meantime  September 24, 2021   \n",
       "97            RP Boo                   Established!  September 17, 2021   \n",
       "98        Billy Idol              The Roadside [EP]  September 17, 2021   \n",
       "99       Moor Mother  Black Encyclopedia of the Air  September 17, 2021   \n",
       "\n",
       "    week_num  meta_score  user_score  \n",
       "0         44          88           0  \n",
       "1         43          85          79  \n",
       "2         43          83          82  \n",
       "3         43          87          93  \n",
       "4         43          57          58  \n",
       "..       ...         ...         ...  \n",
       "95        38          79           0  \n",
       "96        38          80          94  \n",
       "97        37          79           0  \n",
       "98        37          68           0  \n",
       "99        37          83           0  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_df = pd.read_csv(file_path)  \n",
    "# dedup df        \n",
    "# scrape_clean = scrape_df.drop_duplicates(subset = 'artist', ignore_index = True)\n",
    "# scrape_clean\n",
    "scrape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2c7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_review_url(df):\n",
    "###\n",
    "# takes a df latest metascrape, cleans the artist and album strings\n",
    "# and adds a new column of urls to scrape review values\n",
    "###\n",
    "    review_urls = []\n",
    "    # iterate over dataframe\n",
    "    for i, j in df.iterrows():\n",
    "    #     clean album and artist names of all nonalpha except for ! and accent marks\n",
    "        al = re.sub(r'[^-A-Za-z0-9!áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ ]+', '', j['album'])\n",
    "        ar = re.sub(r'[^-A-Za-z0-9!áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ ]+', '', j['artist'])\n",
    "    # correct instances of multilple spaces\n",
    "        al = re.sub(' +', ' ', al)\n",
    "        ar = re.sub(' +', ' ', ar)\n",
    "    # make lowercase and join words with - for url\n",
    "        url_end = f'{al}/{ar}'.replace(\" \", \"-\").lower() \n",
    "    # concat url for review scrape    \n",
    "        url_beginning ='https://www.metacritic.com/music/'\n",
    "        review_urls.append(url_beginning + url_end)\n",
    "# get value of colmuns to use for new column position\n",
    "    new_col_position = len(df.columns)\n",
    "# Use insert to add review_urls column and values to dataframe\n",
    "    df.insert(new_col_position, \"review_urls\", review_urls)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_url_df = create_review_url(scrape_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02700304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>date</th>\n",
       "      <th>week_num</th>\n",
       "      <th>meta_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>review_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snail Mail</td>\n",
       "      <td>Valentine</td>\n",
       "      <td>November 5, 2021</td>\n",
       "      <td>44</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.metacritic.com/music/valentine/sna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The War on Drugs</td>\n",
       "      <td>I Don't Live Here Anymore</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>https://www.metacritic.com/music/i-dont-live-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mastodon</td>\n",
       "      <td>Hushed and Grim</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>https://www.metacritic.com/music/hushed-and-gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geese</td>\n",
       "      <td>Projector</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>https://www.metacritic.com/music/projector/geese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Equals</td>\n",
       "      <td>October 29, 2021</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>https://www.metacritic.com/music/equals/ed-she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mickey Guyton</td>\n",
       "      <td>Remember Her Name</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.metacritic.com/music/remember-her-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Alessia Cara</td>\n",
       "      <td>In the Meantime</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>https://www.metacritic.com/music/in-the-meanti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RP Boo</td>\n",
       "      <td>Established!</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.metacritic.com/music/established!/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>The Roadside [EP]</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.metacritic.com/music/the-roadside-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Moor Mother</td>\n",
       "      <td>Black Encyclopedia of the Air</td>\n",
       "      <td>September 17, 2021</td>\n",
       "      <td>37</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.metacritic.com/music/black-encyclo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                          album                date  \\\n",
       "0         Snail Mail                      Valentine    November 5, 2021   \n",
       "1   The War on Drugs      I Don't Live Here Anymore    October 29, 2021   \n",
       "2           Mastodon                Hushed and Grim    October 29, 2021   \n",
       "3              Geese                      Projector    October 29, 2021   \n",
       "4         Ed Sheeran                         Equals    October 29, 2021   \n",
       "..               ...                            ...                 ...   \n",
       "95     Mickey Guyton              Remember Her Name  September 24, 2021   \n",
       "96      Alessia Cara                In the Meantime  September 24, 2021   \n",
       "97            RP Boo                   Established!  September 17, 2021   \n",
       "98        Billy Idol              The Roadside [EP]  September 17, 2021   \n",
       "99       Moor Mother  Black Encyclopedia of the Air  September 17, 2021   \n",
       "\n",
       "    week_num  meta_score  user_score  \\\n",
       "0         44          88           0   \n",
       "1         43          85          79   \n",
       "2         43          83          82   \n",
       "3         43          87          93   \n",
       "4         43          57          58   \n",
       "..       ...         ...         ...   \n",
       "95        38          79           0   \n",
       "96        38          80          94   \n",
       "97        37          79           0   \n",
       "98        37          68           0   \n",
       "99        37          83           0   \n",
       "\n",
       "                                          review_urls  \n",
       "0   https://www.metacritic.com/music/valentine/sna...  \n",
       "1   https://www.metacritic.com/music/i-dont-live-h...  \n",
       "2   https://www.metacritic.com/music/hushed-and-gr...  \n",
       "3    https://www.metacritic.com/music/projector/geese  \n",
       "4   https://www.metacritic.com/music/equals/ed-she...  \n",
       "..                                                ...  \n",
       "95  https://www.metacritic.com/music/remember-her-...  \n",
       "96  https://www.metacritic.com/music/in-the-meanti...  \n",
       "97  https://www.metacritic.com/music/established!/...  \n",
       "98  https://www.metacritic.com/music/the-roadside-...  \n",
       "99  https://www.metacritic.com/music/black-encyclo...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_url_df\n",
    "###\n",
    "# found an errant / in user reviews and column is of datatype string and don't know why\n",
    "# this fixes that but need to check scrape function to see why\n",
    "###\n",
    "# for _ in scrape_clean_url_df['user_score']:\n",
    "#     if len(_) > 2:\n",
    "#         _=_[:2]\n",
    "#     print(_)\n",
    "# print(scrape_clean_url_df['user_score'])       \n",
    "# scrape_clean_url_df = int(scrape_clean_url_df['user_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1beab92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(df):\n",
    "    ###\n",
    "    # takes a meta_scrape dataframe with review urls and \n",
    "    # scrapes the num of reviews-both critics and users-\n",
    "    # album image, record label and first genre of album\n",
    "    # and returns a dataframe\n",
    "    ###\n",
    "    img = []\n",
    "    crit_num = []\n",
    "    user_num = []\n",
    "    label = []\n",
    "    genre = []\n",
    "\n",
    "    for i, j in df.iterrows():\n",
    "        url = j['review_urls']\n",
    "        user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "        # send response\n",
    "        response_reviews = requests.get(url, headers = user_agent)\n",
    "        # scrape website into variable to parse\n",
    "        soup_reviews = BeautifulSoup(response_reviews.text, 'html.parser')\n",
    "        ########### comment back in from here\n",
    "        # scrape album image \n",
    "        img_soup = soup_reviews.find('meta', property=\"og:image\")\n",
    "        img.append(img_soup['content'])\n",
    "        # scrape num of critical reviews\n",
    "        num_rev=(soup_reviews.find('span', itemprop=\"reviewCount\"))\n",
    "        crit_num.append(num_rev.text.strip())\n",
    "        # scrape num of user reviews\n",
    "        if j['user_score'] == 0:\n",
    "            user_num.append(0)\n",
    "        else:\n",
    "            try:\n",
    "                user_revs = float(soup_reviews.find('div', class_='metascore_w user large album positive').text)\n",
    "                user_num.append(int(user_revs*10))\n",
    "                countpos+=1\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                user_revs = float(soup_reviews.find('div', class_='metascore_w user large album mixed').text)\n",
    "                user_num.append(int(user_revs*10))\n",
    "                countmix+=1\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                user_revs = float(soup_reviews.find('div', class_='metascore_w user large album negative').text)\n",
    "                user_num.append(int(user_revs*10))\n",
    "                countneg+=1\n",
    "            except:\n",
    "                pass\n",
    "        # scrape record labels\n",
    "        label_class = soup_reviews.find_all(\"span\", itemprop=\"name\")\n",
    "        label.append(label_class[2].text.strip())\n",
    "        # scrape genre\n",
    "        genre.append(soup_reviews.find(\"span\", itemprop=\"genre\").text)\n",
    "    # drop column for url and add scrapped lists to dataframe\n",
    "    df = df.drop(columns='review_urls').assign(album_img = img, crit_rev_num = crit_num, user_rev_num = user_num, record_label = label, album_genre = genre)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c342c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = scrape_reviews(scrape_url_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e968382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>date</th>\n",
       "      <th>meta_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>album_img</th>\n",
       "      <th>crit_rev_num</th>\n",
       "      <th>user_rev_num</th>\n",
       "      <th>record_label</th>\n",
       "      <th>album_genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist  album  date  meta_score  user_score  album_img  \\\n",
       "week_num                                                           \n",
       "37             3      3     3           3           3          3   \n",
       "38            14     14    14          14          14         14   \n",
       "39            20     20    20          20          20         20   \n",
       "40            12     12    12          12          12         12   \n",
       "41            18     18    18          18          18         18   \n",
       "42            20     20    20          20          20         20   \n",
       "43            12     12    12          12          12         12   \n",
       "44             1      1     1           1           1          1   \n",
       "\n",
       "          crit_rev_num  user_rev_num  record_label  album_genre  \n",
       "week_num                                                         \n",
       "37                   3             3             3            3  \n",
       "38                  14            14            14           14  \n",
       "39                  20            20            20           20  \n",
       "40                  12            12            12           12  \n",
       "41                  18            18            18           18  \n",
       "42                  20            20            20           20  \n",
       "43                  12            12            12           12  \n",
       "44                   1             1             1            1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(by='week_num').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Connection with MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "# database\n",
    "db = client[\"stocks_database\"]\n",
    "# collection\n",
    "company= db[\"Company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e51304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
